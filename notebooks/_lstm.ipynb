{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e78225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXUSEU</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1812</td>\n",
       "      <td>1999-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1760</td>\n",
       "      <td>1999-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1636</td>\n",
       "      <td>1999-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1672</td>\n",
       "      <td>1999-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1554</td>\n",
       "      <td>1999-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1534</td>\n",
       "      <td>1999-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1548</td>\n",
       "      <td>1999-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1698</td>\n",
       "      <td>1999-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.1689</td>\n",
       "      <td>1999-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.1591</td>\n",
       "      <td>1999-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEXUSEU       date\n",
       "0   1.1812 1999-01-04\n",
       "1   1.1760 1999-01-05\n",
       "2   1.1636 1999-01-06\n",
       "3   1.1672 1999-01-07\n",
       "4   1.1554 1999-01-08\n",
       "5   1.1534 1999-01-11\n",
       "6   1.1548 1999-01-12\n",
       "7   1.1698 1999-01-13\n",
       "8   1.1689 1999-01-14\n",
       "9   1.1591 1999-01-15"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data ingestion and data transformation\n",
    "from src.dataset.data_ingestion import DataIngestion\n",
    "from src.dataset.data_transformation import DataTransformation\n",
    "\n",
    "# pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn metrics and MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# device\n",
    "device = \"cuda\"\n",
    "\n",
    "# import helpers\n",
    "from helpers.sliding_window import sliding_window, convert_array_to_tensor\n",
    "\n",
    "\n",
    "\n",
    "# lstm\n",
    "from src.models.lstm import LSTM\n",
    "\n",
    "# plots through matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load in data\n",
    "SERIES_ID = \"DEXUSEU\"\n",
    "# batch size and window_size\n",
    "BATCH_SIZE = 64\n",
    "WINDOW_SIZE = 14\n",
    "\n",
    "data = DataIngestion(SERIES_ID).fetch_data()\n",
    "data.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3cedf",
   "metadata": {},
   "source": [
    "- Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a06c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 17:50:26 - INFO - tools.logger - 43 - Train Size: 3030\n",
      "2025-12-31 17:50:26 - INFO - tools.logger - 55 - Shape of scaled training data: (3030, 1)\n",
      "2025-12-31 17:50:26 - INFO - tools.logger - 56 - Shape of scaled testing data: (758, 1)\n"
     ]
    }
   ],
   "source": [
    "# from data transformation, transform into scaled training and testing split\n",
    "train, test = DataTransformation(SERIES_ID).split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206be74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sliding window\n",
    "X_train, y_train = sliding_window(train, WINDOW_SIZE)\n",
    "X_test, y_test = sliding_window(test, WINDOW_SIZE)\n",
    "\n",
    "X_train = convert_array_to_tensor(X_train)\n",
    "X_test = convert_array_to_tensor(X_test)\n",
    "y_train = convert_array_to_tensor(y_train)\n",
    "y_test = convert_array_to_tensor(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa1a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru\n",
    "model = LSTM(input_size=1, hidden_size=512, num_layers=2, output_size=1)\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac53813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train_rmse: 0.433; Test rmse: 0.2568\n",
      "Epoch: 1; train_rmse: 0.2884; Test rmse: 0.09859\n",
      "Epoch: 2; train_rmse: 0.3023; Test rmse: 0.3329\n",
      "Epoch: 3; train_rmse: 0.2222; Test rmse: 0.1925\n",
      "Epoch: 4; train_rmse: 0.2211; Test rmse: 0.09097\n",
      "Epoch: 5; train_rmse: 0.24; Test rmse: 0.07191\n",
      "Epoch: 6; train_rmse: 0.2403; Test rmse: 0.07122\n",
      "Epoch: 7; train_rmse: 0.2226; Test rmse: 0.06991\n",
      "Epoch: 8; train_rmse: 0.1952; Test rmse: 0.0901\n",
      "Epoch: 9; train_rmse: 0.1803; Test rmse: 0.1466\n",
      "Epoch: 10; train_rmse: 0.1975; Test rmse: 0.208\n",
      "Epoch: 11; train_rmse: 0.1889; Test rmse: 0.2012\n",
      "Epoch: 12; train_rmse: 0.1534; Test rmse: 0.1383\n",
      "Epoch: 13; train_rmse: 0.1432; Test rmse: 0.07809\n",
      "Epoch: 14; train_rmse: 0.1472; Test rmse: 0.05074\n",
      "Epoch: 15; train_rmse: 0.1337; Test rmse: 0.04423\n",
      "Epoch: 16; train_rmse: 0.08645; Test rmse: 0.03872\n",
      "Epoch: 17; train_rmse: 0.08273; Test rmse: 0.06952\n",
      "Epoch: 18; train_rmse: 0.09317; Test rmse: 0.05186\n",
      "Epoch: 19; train_rmse: 0.0506; Test rmse: 0.05454\n",
      "Epoch: 20; train_rmse: 0.1048; Test rmse: 0.1044\n",
      "Epoch: 21; train_rmse: 0.0846; Test rmse: 0.09478\n",
      "Epoch: 22; train_rmse: 0.05564; Test rmse: 0.04444\n",
      "Epoch: 23; train_rmse: 0.091; Test rmse: 0.02884\n",
      "Epoch: 24; train_rmse: 0.03814; Test rmse: 0.02579\n",
      "Epoch: 25; train_rmse: 0.04959; Test rmse: 0.04158\n",
      "Epoch: 26; train_rmse: 0.06713; Test rmse: 0.04384\n",
      "Epoch: 27; train_rmse: 0.05665; Test rmse: 0.03059\n",
      "Epoch: 28; train_rmse: 0.04048; Test rmse: 0.02922\n",
      "Epoch: 29; train_rmse: 0.05454; Test rmse: 0.05309\n",
      "Epoch: 30; train_rmse: 0.06394; Test rmse: 0.06289\n",
      "Epoch: 31; train_rmse: 0.04934; Test rmse: 0.04868\n",
      "Epoch: 32; train_rmse: 0.04154; Test rmse: 0.02921\n",
      "Epoch: 33; train_rmse: 0.04975; Test rmse: 0.02518\n",
      "Epoch: 34; train_rmse: 0.04945; Test rmse: 0.02705\n",
      "Epoch: 35; train_rmse: 0.03487; Test rmse: 0.02368\n",
      "Epoch: 36; train_rmse: 0.02628; Test rmse: 0.02331\n",
      "Epoch: 37; train_rmse: 0.03989; Test rmse: 0.02813\n",
      "Epoch: 38; train_rmse: 0.03814; Test rmse: 0.02479\n",
      "Epoch: 39; train_rmse: 0.0289; Test rmse: 0.02753\n",
      "Epoch: 40; train_rmse: 0.03744; Test rmse: 0.04001\n",
      "Epoch: 41; train_rmse: 0.04094; Test rmse: 0.04276\n",
      "Epoch: 42; train_rmse: 0.03181; Test rmse: 0.0332\n",
      "Epoch: 43; train_rmse: 0.02729; Test rmse: 0.02337\n",
      "Epoch: 44; train_rmse: 0.03319; Test rmse: 0.02559\n",
      "Epoch: 45; train_rmse: 0.02989; Test rmse: 0.02602\n",
      "Epoch: 46; train_rmse: 0.02438; Test rmse: 0.02262\n",
      "Epoch: 47; train_rmse: 0.02909; Test rmse: 0.02205\n",
      "Epoch: 48; train_rmse: 0.03234; Test rmse: 0.0223\n",
      "Epoch: 49; train_rmse: 0.02923; Test rmse: 0.0222\n",
      "Epoch: 50; train_rmse: 0.02691; Test rmse: 0.02549\n",
      "Epoch: 51; train_rmse: 0.02955; Test rmse: 0.02976\n",
      "Epoch: 52; train_rmse: 0.02894; Test rmse: 0.02871\n",
      "Epoch: 53; train_rmse: 0.02462; Test rmse: 0.02355\n",
      "Epoch: 54; train_rmse: 0.0249; Test rmse: 0.022\n",
      "Epoch: 55; train_rmse: 0.02712; Test rmse: 0.02391\n",
      "Epoch: 56; train_rmse: 0.02573; Test rmse: 0.02385\n",
      "Epoch: 57; train_rmse: 0.02458; Test rmse: 0.02264\n",
      "Epoch: 58; train_rmse: 0.02679; Test rmse: 0.02283\n",
      "Epoch: 59; train_rmse: 0.02667; Test rmse: 0.02281\n",
      "Epoch: 60; train_rmse: 0.02444; Test rmse: 0.02246\n",
      "Epoch: 61; train_rmse: 0.02482; Test rmse: 0.02304\n",
      "Epoch: 62; train_rmse: 0.02536; Test rmse: 0.02287\n",
      "Epoch: 63; train_rmse: 0.024; Test rmse: 0.02184\n",
      "Epoch: 64; train_rmse: 0.0238; Test rmse: 0.02249\n",
      "Epoch: 65; train_rmse: 0.02503; Test rmse: 0.02411\n",
      "Epoch: 66; train_rmse: 0.02473; Test rmse: 0.02384\n",
      "Epoch: 67; train_rmse: 0.02401; Test rmse: 0.02233\n",
      "Epoch: 68; train_rmse: 0.02452; Test rmse: 0.02163\n",
      "Epoch: 69; train_rmse: 0.0245; Test rmse: 0.02161\n",
      "Epoch: 70; train_rmse: 0.02359; Test rmse: 0.02171\n",
      "Epoch: 71; train_rmse: 0.02363; Test rmse: 0.02216\n",
      "Epoch: 72; train_rmse: 0.02404; Test rmse: 0.02232\n",
      "Epoch: 73; train_rmse: 0.02362; Test rmse: 0.02193\n",
      "Epoch: 74; train_rmse: 0.02359; Test rmse: 0.02202\n",
      "Epoch: 75; train_rmse: 0.02402; Test rmse: 0.02242\n",
      "Epoch: 76; train_rmse: 0.02375; Test rmse: 0.0222\n",
      "Epoch: 77; train_rmse: 0.02343; Test rmse: 0.02183\n",
      "Epoch: 78; train_rmse: 0.02363; Test rmse: 0.02191\n",
      "Epoch: 79; train_rmse: 0.02349; Test rmse: 0.02188\n",
      "Epoch: 80; train_rmse: 0.02324; Test rmse: 0.02164\n",
      "Epoch: 81; train_rmse: 0.02345; Test rmse: 0.02154\n",
      "Epoch: 82; train_rmse: 0.02349; Test rmse: 0.02151\n",
      "Epoch: 83; train_rmse: 0.0233; Test rmse: 0.02159\n",
      "Epoch: 84; train_rmse: 0.02338; Test rmse: 0.02187\n",
      "Epoch: 85; train_rmse: 0.02341; Test rmse: 0.02189\n",
      "Epoch: 86; train_rmse: 0.0232; Test rmse: 0.02162\n",
      "Epoch: 87; train_rmse: 0.02321; Test rmse: 0.02151\n",
      "Epoch: 88; train_rmse: 0.02326; Test rmse: 0.02157\n",
      "Epoch: 89; train_rmse: 0.02315; Test rmse: 0.02157\n",
      "Epoch: 90; train_rmse: 0.02317; Test rmse: 0.02158\n",
      "Epoch: 91; train_rmse: 0.02323; Test rmse: 0.0216\n",
      "Epoch: 92; train_rmse: 0.02314; Test rmse: 0.02157\n",
      "Epoch: 93; train_rmse: 0.02312; Test rmse: 0.02157\n",
      "Epoch: 94; train_rmse: 0.02314; Test rmse: 0.02156\n",
      "Epoch: 95; train_rmse: 0.02306; Test rmse: 0.02147\n",
      "Epoch: 96; train_rmse: 0.02304; Test rmse: 0.02146\n",
      "Epoch: 97; train_rmse: 0.02308; Test rmse: 0.02149\n",
      "Epoch: 98; train_rmse: 0.02303; Test rmse: 0.02143\n",
      "Epoch: 99; train_rmse: 0.02302; Test rmse: 0.02137\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred.float(),y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred,y_train))\n",
    "        y_pred_test =  model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred_test,y_test))\n",
    "        print(f'Epoch: {epoch}; train_rmse: {train_rmse:.4}; Test rmse: {test_rmse:.4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afc9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "training = data.iloc[:, 0:1].values\n",
    "scaler.fit(training)\n",
    "\n",
    "# training length\n",
    "train_length = int(len(training) * 0.80)\n",
    "\n",
    "\n",
    "\n",
    "# torch undue scaler from y_pred and y_test\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_np = y_pred.cpu()\n",
    "    y_test_np = y_test.cpu()\n",
    "    pred_rescaled = scaler.inverse_transform(y_pred_np)\n",
    "    actual_rescaled = scaler.inverse_transform(y_test_np)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4727dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 92.90\n",
      "Mean Squared Error: 0.0002735\n",
      "Mean Absolute Percentage Error: 0.0116\n",
      "Mean Absolute Error: 0.012878069414847315\n"
     ]
    }
   ],
   "source": [
    "# r2-score\n",
    "r2 = r2_score(actual_rescaled,pred_rescaled)\n",
    "print(f\"R2 Score: {r2*100:.2f}\")\n",
    "\n",
    "# mean-square error\n",
    "mse = mean_squared_error(actual_rescaled,pred_rescaled)\n",
    "print(f\"Mean Squared Error: {mse:.4}\")\n",
    "\n",
    "\n",
    "# mean absolute percentage error\n",
    "mape = mean_absolute_percentage_error(actual_rescaled,pred_rescaled)\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.4f}\")\n",
    "\n",
    "\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(actual_rescaled,pred_rescaled)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624a6c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  Actual Spot Rate  Predicted Spot Rate\n",
      "0  2016-07-12            1.1074             1.109992\n",
      "1  2016-07-14            1.1109             1.108923\n",
      "2  2016-07-15            1.1059             1.108649\n",
      "3  2016-07-20            1.1007             1.108445\n",
      "4  2016-07-22            1.0968             1.107634\n",
      "5  2016-07-25            1.0980             1.106199\n",
      "6  2016-07-27            1.0988             1.104517\n",
      "7  2016-07-28            1.1094             1.103429\n",
      "8  2016-07-29            1.1168             1.103316\n",
      "9  2016-08-01            1.1176             1.104540\n",
      "10 2016-08-02            1.1225             1.106463\n",
      "11 2016-08-04            1.1134             1.108951\n",
      "12 2016-08-10            1.1171             1.110842\n",
      "13 2016-08-16            1.1277             1.112356\n",
      "14 2016-08-18            1.1334             1.114376\n",
      "15 2016-08-19            1.1326             1.117113\n",
      "16 2016-08-22            1.1314             1.120012\n",
      "17 2016-08-26            1.1237             1.122677\n",
      "18 2016-08-31            1.1146             1.124351\n",
      "19 2016-09-19            1.1179             1.124515\n",
      "          date  Actual Spot Rate  Predicted Spot Rate\n",
      "724 2025-08-26            1.1657             1.164370\n",
      "725 2025-08-27            1.1611             1.164943\n",
      "726 2025-09-17            1.1845             1.164951\n",
      "727 2025-09-18            1.1780             1.166336\n",
      "728 2025-10-07            1.1674             1.168349\n",
      "729 2025-10-10            1.1613             1.169516\n",
      "730 2025-10-15            1.1638             1.169333\n",
      "731 2025-10-28            1.1659             1.168527\n",
      "732 2025-11-03            1.1531             1.168002\n",
      "733 2025-11-04            1.1491             1.166519\n",
      "734 2025-11-05            1.1485             1.164266\n",
      "735 2025-11-06            1.1539             1.161638\n",
      "736 2025-11-10            1.1545             1.159524\n",
      "737 2025-11-14            1.1617             1.158098\n",
      "738 2025-11-18            1.1579             1.157584\n",
      "739 2025-11-21            1.1506             1.157535\n",
      "740 2025-11-25            1.1553             1.157074\n",
      "741 2025-12-09            1.1639             1.156332\n",
      "742 2025-12-12            1.1731             1.156495\n",
      "743 2025-12-19            1.1721             1.158069\n"
     ]
    }
   ],
   "source": [
    "# actual compared to predicted spot rate\n",
    "\n",
    "test_dates = data.iloc[train_length + WINDOW_SIZE:]['date'].reset_index(drop=True)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"date\": test_dates,\n",
    "    \"Actual Spot Rate\": actual_rescaled.flatten(),\n",
    "    \"Predicted Spot Rate\": pred_rescaled.flatten()\n",
    "})\n",
    "\n",
    "print(comparison_df.head(20))\n",
    "print(comparison_df.tail(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
