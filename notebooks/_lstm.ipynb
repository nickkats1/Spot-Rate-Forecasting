{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e78225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXUSEU</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1812</td>\n",
       "      <td>1999-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1760</td>\n",
       "      <td>1999-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1636</td>\n",
       "      <td>1999-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1672</td>\n",
       "      <td>1999-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1554</td>\n",
       "      <td>1999-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1534</td>\n",
       "      <td>1999-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1548</td>\n",
       "      <td>1999-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1698</td>\n",
       "      <td>1999-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.1689</td>\n",
       "      <td>1999-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.1591</td>\n",
       "      <td>1999-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEXUSEU       date\n",
       "0   1.1812 1999-01-04\n",
       "1   1.1760 1999-01-05\n",
       "2   1.1636 1999-01-06\n",
       "3   1.1672 1999-01-07\n",
       "4   1.1554 1999-01-08\n",
       "5   1.1534 1999-01-11\n",
       "6   1.1548 1999-01-12\n",
       "7   1.1698 1999-01-13\n",
       "8   1.1689 1999-01-14\n",
       "9   1.1591 1999-01-15"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data ingestion and data transformation\n",
    "from src.dataset.data_ingestion import DataIngestion\n",
    "from src.dataset.data_transformation import DataTransformation\n",
    "\n",
    "# pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn metrics and MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# device\n",
    "device = \"cuda\"\n",
    "\n",
    "# import helpers\n",
    "from helpers.sliding_window import sliding_window, convert_array_to_tensor\n",
    "\n",
    "\n",
    "\n",
    "# config for lstm\n",
    "\n",
    "\n",
    "# gru\n",
    "from src.models.gru_model import GRUModel\n",
    "from src.models.lstm import LSTM\n",
    "\n",
    "# plots through matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load in data\n",
    "SERIES_ID = \"DEXUSEU\"\n",
    "# batch size and window_size\n",
    "BATCH_SIZE = 64\n",
    "WINDOW_SIZE = 14\n",
    "\n",
    "data = DataIngestion(SERIES_ID).fetch_data()\n",
    "data.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3cedf",
   "metadata": {},
   "source": [
    "- Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a06c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 14:36:25 - INFO - tools.logger - 43 - Train Size: 3333\n",
      "2025-12-31 14:36:25 - INFO - tools.logger - 55 - Shape of scaled training data: (3333, 1)\n",
      "2025-12-31 14:36:25 - INFO - tools.logger - 56 - Shape of scaled testing data: (455, 1)\n"
     ]
    }
   ],
   "source": [
    "# from data transformation, transform into scaled training and testing split\n",
    "train, test = DataTransformation(SERIES_ID).split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206be74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sliding window\n",
    "X_train, y_train = sliding_window(train, WINDOW_SIZE)\n",
    "X_test, y_test = sliding_window(test, WINDOW_SIZE)\n",
    "\n",
    "X_train = convert_array_to_tensor(X_train)\n",
    "X_test = convert_array_to_tensor(X_test)\n",
    "y_train = convert_array_to_tensor(y_train)\n",
    "y_test = convert_array_to_tensor(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa1a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru\n",
    "model = LSTM(input_size=1, hidden_size=512, num_layers=1, output_size=1)\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac53813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train_rmse: 0.4996; Test rmse: 0.3247\n",
      "Epoch: 1; train_rmse: 0.4209; Test rmse: 0.2437\n",
      "Epoch: 2; train_rmse: 0.3201; Test rmse: 0.139\n",
      "Epoch: 3; train_rmse: 0.199; Test rmse: 0.1114\n",
      "Epoch: 4; train_rmse: 0.4687; Test rmse: 0.5292\n",
      "Epoch: 5; train_rmse: 0.2203; Test rmse: 0.2377\n",
      "Epoch: 6; train_rmse: 0.2056; Test rmse: 0.09135\n",
      "Epoch: 7; train_rmse: 0.2527; Test rmse: 0.08022\n",
      "Epoch: 8; train_rmse: 0.2858; Test rmse: 0.1073\n",
      "Epoch: 9; train_rmse: 0.3045; Test rmse: 0.1261\n",
      "Epoch: 10; train_rmse: 0.3133; Test rmse: 0.1356\n",
      "Epoch: 11; train_rmse: 0.315; Test rmse: 0.138\n",
      "Epoch: 12; train_rmse: 0.3113; Test rmse: 0.1348\n",
      "Epoch: 13; train_rmse: 0.3029; Test rmse: 0.127\n",
      "Epoch: 14; train_rmse: 0.2901; Test rmse: 0.1151\n",
      "Epoch: 15; train_rmse: 0.2731; Test rmse: 0.09977\n",
      "Epoch: 16; train_rmse: 0.2519; Test rmse: 0.08282\n",
      "Epoch: 17; train_rmse: 0.2269; Test rmse: 0.07074\n",
      "Epoch: 18; train_rmse: 0.2006; Test rmse: 0.07897\n",
      "Epoch: 19; train_rmse: 0.1809; Test rmse: 0.117\n",
      "Epoch: 20; train_rmse: 0.1841; Test rmse: 0.1767\n",
      "Epoch: 21; train_rmse: 0.2111; Test rmse: 0.2353\n",
      "Epoch: 22; train_rmse: 0.224; Test rmse: 0.2553\n",
      "Epoch: 23; train_rmse: 0.2091; Test rmse: 0.2338\n",
      "Epoch: 24; train_rmse: 0.186; Test rmse: 0.1922\n",
      "Epoch: 25; train_rmse: 0.1723; Test rmse: 0.1502\n",
      "Epoch: 26; train_rmse: 0.1706; Test rmse: 0.1172\n",
      "Epoch: 27; train_rmse: 0.175; Test rmse: 0.09494\n",
      "Epoch: 28; train_rmse: 0.1802; Test rmse: 0.08189\n",
      "Epoch: 29; train_rmse: 0.1833; Test rmse: 0.07529\n",
      "Epoch: 30; train_rmse: 0.1834; Test rmse: 0.07277\n",
      "Epoch: 31; train_rmse: 0.1803; Test rmse: 0.07316\n",
      "Epoch: 32; train_rmse: 0.1745; Test rmse: 0.07657\n",
      "Epoch: 33; train_rmse: 0.1668; Test rmse: 0.08383\n",
      "Epoch: 34; train_rmse: 0.1587; Test rmse: 0.09565\n",
      "Epoch: 35; train_rmse: 0.1524; Test rmse: 0.1117\n",
      "Epoch: 36; train_rmse: 0.1497; Test rmse: 0.1303\n",
      "Epoch: 37; train_rmse: 0.1509; Test rmse: 0.1479\n",
      "Epoch: 38; train_rmse: 0.1532; Test rmse: 0.1598\n",
      "Epoch: 39; train_rmse: 0.152; Test rmse: 0.1616\n",
      "Epoch: 40; train_rmse: 0.1458; Test rmse: 0.1521\n",
      "Epoch: 41; train_rmse: 0.1369; Test rmse: 0.1343\n",
      "Epoch: 42; train_rmse: 0.1296; Test rmse: 0.1133\n",
      "Epoch: 43; train_rmse: 0.1261; Test rmse: 0.09377\n",
      "Epoch: 44; train_rmse: 0.1249; Test rmse: 0.07874\n",
      "Epoch: 45; train_rmse: 0.1231; Test rmse: 0.06922\n",
      "Epoch: 46; train_rmse: 0.1181; Test rmse: 0.06491\n",
      "Epoch: 47; train_rmse: 0.1088; Test rmse: 0.06558\n",
      "Epoch: 48; train_rmse: 0.09686; Test rmse: 0.07168\n",
      "Epoch: 49; train_rmse: 0.08775; Test rmse: 0.08228\n",
      "Epoch: 50; train_rmse: 0.08598; Test rmse: 0.09104\n",
      "Epoch: 51; train_rmse: 0.08114; Test rmse: 0.08577\n",
      "Epoch: 52; train_rmse: 0.06259; Test rmse: 0.06133\n",
      "Epoch: 53; train_rmse: 0.05014; Test rmse: 0.03433\n",
      "Epoch: 54; train_rmse: 0.05543; Test rmse: 0.03364\n",
      "Epoch: 55; train_rmse: 0.05031; Test rmse: 0.03973\n",
      "Epoch: 56; train_rmse: 0.04005; Test rmse: 0.03386\n",
      "Epoch: 57; train_rmse: 0.0627; Test rmse: 0.02988\n",
      "Epoch: 58; train_rmse: 0.05363; Test rmse: 0.04715\n",
      "Epoch: 59; train_rmse: 0.06156; Test rmse: 0.07139\n",
      "Epoch: 60; train_rmse: 0.06168; Test rmse: 0.0716\n",
      "Epoch: 61; train_rmse: 0.04884; Test rmse: 0.05019\n",
      "Epoch: 62; train_rmse: 0.05249; Test rmse: 0.03183\n",
      "Epoch: 63; train_rmse: 0.04229; Test rmse: 0.02987\n",
      "Epoch: 64; train_rmse: 0.03528; Test rmse: 0.0344\n",
      "Epoch: 65; train_rmse: 0.03929; Test rmse: 0.03532\n",
      "Epoch: 66; train_rmse: 0.03641; Test rmse: 0.02968\n",
      "Epoch: 67; train_rmse: 0.03294; Test rmse: 0.02645\n",
      "Epoch: 68; train_rmse: 0.03729; Test rmse: 0.03174\n",
      "Epoch: 69; train_rmse: 0.03965; Test rmse: 0.03513\n",
      "Epoch: 70; train_rmse: 0.03726; Test rmse: 0.03261\n",
      "Epoch: 71; train_rmse: 0.03724; Test rmse: 0.02907\n",
      "Epoch: 72; train_rmse: 0.0392; Test rmse: 0.02773\n",
      "Epoch: 73; train_rmse: 0.03833; Test rmse: 0.02754\n",
      "Epoch: 74; train_rmse: 0.03526; Test rmse: 0.02833\n",
      "Epoch: 75; train_rmse: 0.03417; Test rmse: 0.03034\n",
      "Epoch: 76; train_rmse: 0.03421; Test rmse: 0.03089\n",
      "Epoch: 77; train_rmse: 0.03158; Test rmse: 0.02813\n",
      "Epoch: 78; train_rmse: 0.02885; Test rmse: 0.0255\n",
      "Epoch: 79; train_rmse: 0.02909; Test rmse: 0.02638\n",
      "Epoch: 80; train_rmse: 0.02888; Test rmse: 0.02774\n",
      "Epoch: 81; train_rmse: 0.02716; Test rmse: 0.02716\n",
      "Epoch: 82; train_rmse: 0.02763; Test rmse: 0.02608\n",
      "Epoch: 83; train_rmse: 0.02905; Test rmse: 0.02607\n",
      "Epoch: 84; train_rmse: 0.0284; Test rmse: 0.02763\n",
      "Epoch: 85; train_rmse: 0.02836; Test rmse: 0.03079\n",
      "Epoch: 86; train_rmse: 0.02913; Test rmse: 0.0327\n",
      "Epoch: 87; train_rmse: 0.02823; Test rmse: 0.03125\n",
      "Epoch: 88; train_rmse: 0.02714; Test rmse: 0.02813\n",
      "Epoch: 89; train_rmse: 0.02713; Test rmse: 0.02619\n",
      "Epoch: 90; train_rmse: 0.02638; Test rmse: 0.02572\n",
      "Epoch: 91; train_rmse: 0.02536; Test rmse: 0.02595\n",
      "Epoch: 92; train_rmse: 0.02546; Test rmse: 0.02626\n",
      "Epoch: 93; train_rmse: 0.02553; Test rmse: 0.02587\n",
      "Epoch: 94; train_rmse: 0.02513; Test rmse: 0.02514\n",
      "Epoch: 95; train_rmse: 0.02525; Test rmse: 0.02507\n",
      "Epoch: 96; train_rmse: 0.02562; Test rmse: 0.0254\n",
      "Epoch: 97; train_rmse: 0.02544; Test rmse: 0.02532\n",
      "Epoch: 98; train_rmse: 0.02522; Test rmse: 0.02505\n",
      "Epoch: 99; train_rmse: 0.02531; Test rmse: 0.025\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred.float(),y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred,y_train))\n",
    "        y_pred_test =  model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred_test,y_test))\n",
    "        print(f'Epoch: {epoch}; train_rmse: {train_rmse:.4}; Test rmse: {test_rmse:.4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afc9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "training = data.iloc[:, 0:1].values\n",
    "scaler.fit(training)\n",
    "\n",
    "# training length\n",
    "train_length = int(len(training) * 0.88)\n",
    "\n",
    "\n",
    "\n",
    "# torch undue scaler from y_pred and y_test\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_np = y_pred.cpu()\n",
    "    y_test_np = y_test.cpu()\n",
    "    pred_rescaled = scaler.inverse_transform(y_pred_np)\n",
    "    actual_rescaled = scaler.inverse_transform(y_test_np)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4727dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 91.02\n",
      "Mean Squared Error: 0.0003745\n",
      "Mean Absolute Percentage Error: 0.0138\n",
      "Mean Absolute Error: 0.015142834313669981\n"
     ]
    }
   ],
   "source": [
    "# r2-score\n",
    "r2 = r2_score(actual_rescaled,pred_rescaled)\n",
    "print(f\"R2 Score: {r2*100:.2f}\")\n",
    "\n",
    "# mean-square error\n",
    "mse = mean_squared_error(actual_rescaled,pred_rescaled)\n",
    "print(f\"Mean Squared Error: {mse:.4}\")\n",
    "\n",
    "\n",
    "# mean absolute percentage error\n",
    "mape = mean_absolute_percentage_error(actual_rescaled,pred_rescaled)\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.4f}\")\n",
    "\n",
    "\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(actual_rescaled,pred_rescaled)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624a6c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  Actual Spot Rate  Predicted Spot Rate\n",
      "0  2019-09-26            1.0938             1.105866\n",
      "1  2019-09-27            1.0942             1.104107\n",
      "2  2019-09-30            1.0905             1.102412\n",
      "3  2019-10-02            1.0951             1.100682\n",
      "4  2019-10-04            1.0974             1.099436\n",
      "5  2019-10-15            1.1036             1.098639\n",
      "6  2019-10-17            1.1129             1.098563\n",
      "7  2019-10-18            1.1155             1.099535\n",
      "8  2019-10-23            1.1118             1.101091\n",
      "9  2019-10-25            1.1081             1.102697\n",
      "10 2019-10-30            1.1123             1.103697\n",
      "11 2019-11-01            1.1169             1.104906\n",
      "12 2019-11-08            1.1019             1.106283\n",
      "13 2019-11-12            1.1017             1.106504\n",
      "14 2019-11-21            1.1067             1.106368\n",
      "15 2019-11-22            1.1029             1.106521\n",
      "16 2019-11-25            1.1009             1.106383\n",
      "17 2019-11-26            1.1012             1.106066\n",
      "18 2019-12-12            1.1115             1.105584\n",
      "19 2019-12-13            1.1128             1.105892\n",
      "          date  Actual Spot Rate  Predicted Spot Rate\n",
      "421 2025-08-26            1.1657             1.161376\n",
      "422 2025-08-27            1.1611             1.161886\n",
      "423 2025-09-17            1.1845             1.161770\n",
      "424 2025-09-18            1.1780             1.163245\n",
      "425 2025-10-07            1.1674             1.164869\n",
      "426 2025-10-10            1.1613             1.165544\n",
      "427 2025-10-15            1.1638             1.165167\n",
      "428 2025-10-28            1.1659             1.164541\n",
      "429 2025-11-03            1.1531             1.164499\n",
      "430 2025-11-04            1.1491             1.163239\n",
      "431 2025-11-05            1.1485             1.161443\n",
      "432 2025-11-06            1.1539             1.159377\n",
      "433 2025-11-10            1.1545             1.157803\n",
      "434 2025-11-14            1.1617             1.156665\n",
      "435 2025-11-18            1.1579             1.156118\n",
      "436 2025-11-21            1.1506             1.155753\n",
      "437 2025-11-25            1.1553             1.154963\n",
      "438 2025-12-09            1.1639             1.153935\n",
      "439 2025-12-12            1.1731             1.153936\n",
      "440 2025-12-19            1.1721             1.155255\n"
     ]
    }
   ],
   "source": [
    "# actual compared to predicted spot rate\n",
    "\n",
    "test_dates = data.iloc[train_length + WINDOW_SIZE:]['date'].reset_index(drop=True)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"date\": test_dates,\n",
    "    \"Actual Spot Rate\": actual_rescaled.flatten(),\n",
    "    \"Predicted Spot Rate\": pred_rescaled.flatten()\n",
    "})\n",
    "\n",
    "print(comparison_df.head(20))\n",
    "print(comparison_df.tail(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
